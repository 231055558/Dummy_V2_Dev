#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæœºæ¢°è‡‚è™šæ‹Ÿç›¸æœºç‚¹äº‘ç”Ÿæˆå™¨
æ€è·¯ï¼šè·å–RGBå›¾åƒå’Œæ·±åº¦å›¾åƒï¼Œæ ¹æ®æ·±åº¦ç»™æ¯ä¸ªåƒç´ èµ‹äºˆ3Dä½ç½®ï¼Œé¢œè‰²æ¥è‡ªRGBå›¾åƒ
"""

import sys
import os
import math
import time
import threading
import numpy as np
import cv2

# æ·»åŠ CLI-Toolè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), "CLI_Tool"))


import pybullet as p
import pybullet_data
import open3d as o3d


class SimplePointCloudCamera:
    """
    ç®€åŒ–ç‰ˆè™šæ‹Ÿç›¸æœºç‚¹äº‘ç”Ÿæˆå™¨
    """
    
    def __init__(self):
        # PyBulletä»¿çœŸç¯å¢ƒç›¸å…³
        self.physics_client = None
        self.robot_id = None
        self.joint_indices = []
        self.joint_names = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']
        
        # æœºæ¢°è‡‚çŠ¶æ€
        self.current_joint_angles = [0.0, 60.0, 90.0, 90.0, 0.0, 0.0]  # ä½¿èƒ½çŠ¶æ€
        
        self.camera_offset = [0.0, 0.06, 0.0]  # ç›¸æœºåç§»
        self.camera_fov = 120.0 
        self.camera_near = 0.01
        self.camera_far = 2.0
        self.image_width = 640
        self.image_height = 480
        
        # ç‚¹äº‘å‚æ•°
        self.downsample = 1  # æ¯3ä¸ªåƒç´ å–ä¸€ä¸ªç‚¹
        self.depth_min = 0.05
        self.depth_max = 1.0
        
        # æœ«ç«¯æ‰§è¡Œå™¨è¿æ†ç´¢å¼•
        self.end_effector_link_index = 7
        
        # æ§åˆ¶
        self.running = True
        self.selected_joint = 0
        self.angle_step = 5.0
        
        print("ğŸ“¹ ç®€åŒ–ç‰ˆè™šæ‹Ÿç›¸æœºç‚¹äº‘ç”Ÿæˆå™¨")
        print("æ€è·¯ï¼šåƒç´ â†’3Dç‚¹â†’Open3Dæ˜¾ç¤º")
        print("=" * 50)
    
    def start_pybullet(self):
        """å¯åŠ¨PyBullet"""
        print("ğŸ”§ å¯åŠ¨PyBullet...")
        
        self.physics_client = p.connect(p.GUI)
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        p.setGravity(0, 0, -9.81)
        
        # åŠ è½½åœ°é¢å’Œæœºæ¢°è‡‚
        p.loadURDF("plane.urdf", [0, 0, 0])
        
        urdf_path = os.path.join(os.path.dirname(os.path.dirname(
            os.path.realpath(__file__))), "dummy2", "dummy2.urdf")
        self.robot_id = p.loadURDF(urdf_path, [0, 0, 0], useFixedBase=True)
        
        # è·å–å…³èŠ‚ä¿¡æ¯
        self.get_joint_info()
        
        # æ·»åŠ ä¸€äº›å½©è‰²ç‰©ä½“
        self.add_colorful_objects()
        
        print("âœ… PyBulletå¯åŠ¨æˆåŠŸ")
        return True
    
    def get_joint_info(self):
        """è·å–å…³èŠ‚ä¿¡æ¯"""
        num_joints = p.getNumJoints(self.robot_id)
        self.joint_indices = []
        
        for i in range(num_joints):
            joint_info = p.getJointInfo(self.robot_id, i)
            joint_name = joint_info[1].decode('utf-8')
            
            if joint_name in self.joint_names:
                joint_index = self.joint_names.index(joint_name)
                while len(self.joint_indices) <= joint_index:
                    self.joint_indices.append(-1)
                self.joint_indices[joint_index] = i
    
    def add_colorful_objects(self):
        """æ·»åŠ ä¸€äº›å½©è‰²ç‰©ä½“ç”¨äºæµ‹è¯•"""
        print("ğŸ¨ æ·»åŠ å½©è‰²æµ‹è¯•ç‰©ä½“...")
        
        # çº¢ç»¿è“é»„å››ä¸ªç«‹æ–¹ä½“
        colors = [[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [1, 1, 0, 1]]
        positions = [[0.3, 0.3, 0.05], [0.3, -0.3, 0.05], [-0.3, 0.3, 0.05], [-0.3, -0.3, 0.05]]
        
        for pos, color in zip(positions, colors):
            p.createMultiBody(
                baseMass=0.1,
                baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.05, 0.05, 0.05]),
                baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.05, 0.05, 0.05], rgbaColor=color),
                basePosition=pos
            )
        
        # æ·»åŠ ä¸€ä¸ªè´§æ¶
        shelf_pos = [0.0, 0.5, 0.0]
        shelf_color = [0.8, 0.8, 0.8, 1.0]
        
        # è´§æ¶åº•æ¿
        p.createMultiBody(
            baseMass=0,
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.2, 0.05, 0.01]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.2, 0.05, 0.01], rgbaColor=shelf_color),
            basePosition=[shelf_pos[0], shelf_pos[1], shelf_pos[2] + 0.01]
        )
        
        # è´§æ¶ä¸Šçš„ç‰©å“
        item_colors = [[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1]]
        item_positions = [
            [shelf_pos[0] - 0.1, shelf_pos[1], shelf_pos[2] + 0.05],
            [shelf_pos[0], shelf_pos[1], shelf_pos[2] + 0.05],
            [shelf_pos[0] + 0.1, shelf_pos[1], shelf_pos[2] + 0.05]
        ]
        
        for pos, color in zip(item_positions, item_colors):
            p.createMultiBody(
                baseMass=0.05,
                baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.03, 0.03, 0.03]),
                baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.03, 0.03, 0.03], rgbaColor=color),
                basePosition=pos
            )
    
    def update_robot_pose(self):
        """æ›´æ–°æœºæ¢°è‡‚å§¿æ€"""
        for i, joint_idx in enumerate(self.joint_indices):
            if joint_idx != -1:
                angle_rad = math.radians(self.current_joint_angles[i])
                p.resetJointState(self.robot_id, joint_idx, angle_rad)
    
    def get_camera_pose(self):
        """è·å–ç›¸æœºä½ç½®å’Œæœå‘"""
        # è·å–æœ«ç«¯æ³•å…°ä½ç½®å§¿æ€
        link_state = p.getLinkState(self.robot_id, self.end_effector_link_index, computeForwardKinematics=True)
        flange_position = list(link_state[0])
        flange_orientation = list(link_state[1])
        
        # è®¡ç®—ç›¸æœºä½ç½®
        rotation_matrix = np.array(p.getMatrixFromQuaternion(flange_orientation)).reshape(3, 3)
        camera_offset_global = rotation_matrix @ np.array(self.camera_offset)
        camera_position = np.array(flange_position) + camera_offset_global
        
        # ç›¸æœºæœå‘ï¼ˆYè½´æ­£æ–¹å‘ä¸ºå‰æ–¹ï¼‰
        forward_direction = rotation_matrix @ np.array([0, 1, 0])
        camera_target = camera_position + forward_direction * 0.3
        
        return camera_position.tolist(), camera_target.tolist()
    
    def capture_rgbd(self):
        """æ•è·RGBå›¾åƒå’Œæ·±åº¦å›¾åƒ"""
        camera_position, camera_target = self.get_camera_pose()
        
        # è®¡ç®—è§†å›¾çŸ©é˜µå’ŒæŠ•å½±çŸ©é˜µ
        view_matrix = p.computeViewMatrix(
            cameraEyePosition=camera_position,
            cameraTargetPosition=camera_target,
            cameraUpVector=[0, 0, 1]
        )
        
        projection_matrix = p.computeProjectionMatrixFOV(
            fov=self.camera_fov,
            aspect=1.0,
            nearVal=self.camera_near,
            farVal=self.camera_far
        )
        
        # æ¸²æŸ“å›¾åƒ
        width, height, rgb_img, depth_img, seg_img = p.getCameraImage(
            width=self.image_width,
            height=self.image_height,
            viewMatrix=view_matrix,
            projectionMatrix=projection_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL
        )
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        rgb_array = np.array(rgb_img, dtype=np.uint8)
        rgb_array = rgb_array[:, :, :3]  # å»æ‰alphaé€šé“
        
        depth_array = np.array(depth_img).reshape(height, width)
        # è½¬æ¢ä¸ºå®é™…æ·±åº¦å€¼
        depth_real = self.camera_far * self.camera_near / (self.camera_far - (self.camera_far - self.camera_near) * depth_array)
        
        return rgb_array, depth_real, camera_position, camera_target
    
    def pixels_to_pointcloud(self, rgb_image, depth_image, camera_position, camera_target):
        """
        å°†åƒç´ è½¬æ¢ä¸ºç‚¹äº‘
        æ ¸å¿ƒæ€è·¯ï¼šæ¯ä¸ªåƒç´  â†’ æ ¹æ®æ·±åº¦å€¼ â†’ 3Dç©ºé—´ä½ç½® + RGBé¢œè‰²
        """
        points = []
        colors = []
        
        height, width = depth_image.shape
        
        # è®¡ç®—ç›¸æœºå†…å‚ï¼ˆä»FOVæ¨å¯¼ç„¦è·ï¼‰
        fov_rad = math.radians(self.camera_fov)
        focal_length = (height / 2.0) / math.tan(fov_rad / 2.0)
        cx, cy = width / 2.0, height / 2.0
        
        # è®¡ç®—ç›¸æœºåæ ‡ç³»åˆ°ä¸–ç•Œåæ ‡ç³»çš„å˜æ¢
        camera_pos = np.array(camera_position)
        target_pos = np.array(camera_target)
        
        # ç›¸æœºåæ ‡ç³»æ–¹å‘å‘é‡
        forward = target_pos - camera_pos
        forward = forward / np.linalg.norm(forward)
        up = np.array([0, 0, 1])
        right = np.cross(forward, up)
        right = right / np.linalg.norm(right)
        up = np.cross(right, forward)
        
        # æ—‹è½¬çŸ©é˜µï¼šç›¸æœºåæ ‡ç³» â†’ ä¸–ç•Œåæ ‡ç³»
        R = np.column_stack([right, -up, forward])
        
        # éå†åƒç´ ï¼ˆä¸‹é‡‡æ ·ï¼‰
        for v in range(0, height, self.downsample):
            for u in range(0, width, self.downsample):
                depth = depth_image[v, u]
                
                # è¿‡æ»¤æ— æ•ˆæ·±åº¦
                if depth < self.depth_min or depth > self.depth_max:
                    continue
                
                # åƒç´ åæ ‡ â†’ ç›¸æœºåæ ‡ç³»
                x_cam = (u - cx) * depth / focal_length
                y_cam = (v - cy) * depth / focal_length
                z_cam = depth
                
                # ç›¸æœºåæ ‡ç³» â†’ ä¸–ç•Œåæ ‡ç³»
                point_cam = np.array([x_cam, y_cam, z_cam])
                point_world = camera_pos + R @ point_cam
                
                # è·å–åƒç´ é¢œè‰²
                pixel_color = rgb_image[v, u] / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
                
                points.append(point_world)
                colors.append(pixel_color)
        
        return np.array(points), np.array(colors)
    
    def show_pointcloud(self, points, colors):
        """åœ¨Open3Dä¸­æ˜¾ç¤ºç‚¹äº‘ï¼ˆåœ†å½¢ç‚¹ï¼‰"""
        # åˆ›å»ºç‚¹äº‘å¯¹è±¡
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # åˆ›å»ºåæ ‡è½´
        coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)
        
        # åˆ›å»ºå¯è§†åŒ–å™¨å¹¶è®¾ç½®åœ†å½¢ç‚¹æ¸²æŸ“
        vis = o3d.visualization.Visualizer()
        vis.create_window(window_name="ç®€åŒ–ç‰ˆç‚¹äº‘ï¼ˆåœ†å½¢ç‚¹ï¼‰", width=800, height=600)
        
        # æ·»åŠ å‡ ä½•ä½“
        vis.add_geometry(pcd)
        vis.add_geometry(coordinate_frame)
        
        # è·å–æ¸²æŸ“é€‰é¡¹å¹¶è®¾ç½®ç‚¹ä¸ºåœ†å½¢
        render_option = vis.get_render_option()
        render_option.point_show_normal = False
        render_option.point_size = 3.0  # è®¾ç½®ç‚¹çš„å¤§å°
        render_option.point_color_option = o3d.visualization.PointColorOption.Color
        
        # è®¾ç½®èƒŒæ™¯é¢œè‰²
        render_option.background_color = np.array([0.1, 0.1, 0.1])  # æ·±ç°è‰²èƒŒæ™¯
        
        print("ğŸ¯ ç‚¹äº‘æ˜¾ç¤ºè¯´æ˜:")
        print("   - é¼ æ ‡å·¦é”®æ‹–æ‹½: æ—‹è½¬è§†è§’")
        print("   - é¼ æ ‡å³é”®æ‹–æ‹½: å¹³ç§»è§†è§’") 
        print("   - æ»šè½®: ç¼©æ”¾")
        print("   - æŒ‰Qæˆ–å…³é—­çª—å£: é€€å‡ºæ˜¾ç¤º")
        
        # è¿è¡Œå¯è§†åŒ–
        vis.run()
        vis.destroy_window()
    
    def run_once(self):
        """è¿è¡Œä¸€æ¬¡ç‚¹äº‘ç”Ÿæˆå’Œæ˜¾ç¤º"""
        print("ğŸ”„ æ›´æ–°æœºæ¢°è‡‚å§¿æ€...")
        self.update_robot_pose()
        p.stepSimulation()
        
        print("ğŸ“· æ•è·RGB-Då›¾åƒ...")
        rgb_image, depth_image, camera_position, camera_target = self.capture_rgbd()
        
        print(f"ğŸ“Š å›¾åƒä¿¡æ¯ - RGBå½¢çŠ¶: {rgb_image.shape}, æ·±åº¦èŒƒå›´: {depth_image.min():.3f}-{depth_image.max():.3f}")
        
        print("ğŸ”„ è½¬æ¢åƒç´ åˆ°ç‚¹äº‘...")
        points, colors = self.pixels_to_pointcloud(rgb_image, depth_image, camera_position, camera_target)
        
        print(f"ğŸ¨ ç‚¹äº‘ä¿¡æ¯ - ç‚¹æ•°: {len(points)}, ç›¸æœºä½ç½®: {[f'{p:.3f}' for p in camera_position]}")
        
        if len(points) > 0:
            print("ğŸ¯ æ˜¾ç¤ºç‚¹äº‘...")
            self.show_pointcloud(points, colors)
        else:
            print("âŒ æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆç‚¹äº‘")
    
    def interactive_control(self):
        """äº¤äº’æ§åˆ¶"""
        print("\nğŸ’¬ äº¤äº’æ§åˆ¶æ¨¡å¼")
        print("å‘½ä»¤: joint <1-6>, up, down, show, quit")
        
        while self.running:
            try:
                command = input("è¯·è¾“å…¥å‘½ä»¤: ").strip().lower()
                
                if command == 'quit':
                    break
                elif command.startswith('joint '):
                    joint_num = int(command.split()[1])
                    if 1 <= joint_num <= 6:
                        self.selected_joint = joint_num - 1
                        print(f"ğŸ¯ é€‰ä¸­å…³èŠ‚ J{joint_num}")
                elif command == 'up':
                    self.current_joint_angles[self.selected_joint] += self.angle_step
                    print(f"â¬†ï¸ J{self.selected_joint + 1}: {self.current_joint_angles[self.selected_joint]:.1f}Â°")
                elif command == 'down':
                    self.current_joint_angles[self.selected_joint] -= self.angle_step
                    print(f"â¬‡ï¸ J{self.selected_joint + 1}: {self.current_joint_angles[self.selected_joint]:.1f}Â°")
                elif command == 'show':
                    self.run_once()
                elif command == 'help':
                    print("å‘½ä»¤è¯´æ˜:")
                    print("  joint <1-6> - é€‰æ‹©å…³èŠ‚")
                    print("  up/down     - è°ƒæ•´å…³èŠ‚è§’åº¦")
                    print("  show        - ç”Ÿæˆå¹¶æ˜¾ç¤ºç‚¹äº‘")
                    print("  quit        - é€€å‡º")
                else:
                    print("âŒ æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
                    
            except Exception as e:
                print(f"âŒ å‘½ä»¤æ‰§è¡Œé”™è¯¯: {e}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.physics_client is not None:
            p.disconnect()

def main():
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆè™šæ‹Ÿç›¸æœºç‚¹äº‘ç”Ÿæˆå™¨")
    
    camera = SimplePointCloudCamera()
    
    try:
        # å¯åŠ¨PyBullet
        if not camera.start_pybullet():
            return
        
        # é¦–æ¬¡æ¼”ç¤º
        print("\nğŸ¬ é¦–æ¬¡æ¼”ç¤º...")
        camera.run_once()
        
        # äº¤äº’æ§åˆ¶
        camera.interactive_control()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        camera.cleanup()
        print("ğŸ”š ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main() 