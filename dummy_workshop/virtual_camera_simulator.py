#!/usr/bin/env python3
"""
æœºæ¢°è‡‚è™šæ‹Ÿç›¸æœºæ¨¡æ‹Ÿå™¨ï¼ˆé›†æˆä½¿èƒ½è¿‡ç¨‹+ç‚¹äº‘ç”Ÿæˆç‰ˆæœ¬ï¼‰
ç›®çš„ï¼š
- ä»æœªä½¿èƒ½çŠ¶æ€å¹³æ»‘è¿‡æ¸¡åˆ°ä½¿èƒ½çŠ¶æ€
- åœ¨æœºæ¢°è‡‚æœ«ç«¯æ³•å…°yè½´æ–¹å‘ï¼ˆç»¿è‰²è½´ï¼‰å®‰è£…è™šæ‹Ÿç›¸æœº
- æ˜¾ç¤ºç›¸æœºè§†è§’ç”»é¢
- ä½¿ç”¨Open3Dç”Ÿæˆå®æ—¶ç‚¹äº‘
- æ”¯æŒç»ˆç«¯äº¤äº’æ§åˆ¶
"""

import sys
import os
import math
import time
import threading
import numpy as np
import cv2

# æ·»åŠ CLI-Toolè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), "CLI-Tool"))

try:
    import pybullet as p
    import pybullet_data
    import open3d as o3d
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·å®‰è£…: pip install pybullet opencv-python open3d")
    sys.exit(1)

class VirtualCameraWithPointCloud:
    """
    é›†æˆä½¿èƒ½è¿‡ç¨‹å’Œç‚¹äº‘ç”Ÿæˆçš„è™šæ‹Ÿç›¸æœºæ¨¡æ‹Ÿå™¨
    """
    
    def __init__(self):
        # PyBulletä»¿çœŸç¯å¢ƒç›¸å…³
        self.physics_client = None
        self.robot_id = None
        self.joint_indices = []
        self.joint_names = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']
        
        # æœºæ¢°è‡‚çŠ¶æ€å®šä¹‰
        self.disabled_state = [0.0, 70.0, 90.0, 0.0, 0.0, 0.0]  # æœªä½¿èƒ½çŠ¶æ€
        self.ready_state = [0.0, 60.0, 60.0, 90.0, 0.0, 0.0]    # ä½¿èƒ½é¢„å¤‡çŠ¶æ€
        self.current_joint_angles = self.disabled_state.copy()
        
        # ä½¿èƒ½å‚æ•°
        self.enable_duration = 3.0
        self.enable_steps = 120
        self.is_enabled = False
        
        # ç›¸æœºç›¸å…³å‚æ•°ï¼ˆè°ƒæ•´åˆ°yè½´æ–¹å‘ï¼Œæ›´é è¿‘ï¼‰
        self.camera_offset = [0.0, 0.06, 0.0]  # ç›¸æœºç›¸å¯¹äºæœ«ç«¯æ³•å…°çš„åç§»ï¼ˆyè½´å‰æ–¹6cmï¼‰
        self.camera_fov = 120.0      # è§†é‡è§’åº¦ï¼ˆåº¦ï¼‰
        self.camera_aspect = 1.0    # ç”»é¢å®½é«˜æ¯”
        self.camera_near = 0.01     # è¿‘æˆªé¢è·ç¦»
        self.camera_far = 2.0       # è¿œæˆªé¢è·ç¦»
        self.image_width = 640      # å›¾åƒå®½åº¦
        self.image_height = 480     # å›¾åƒé«˜åº¦
        
        # ç‚¹äº‘ç›¸å…³å‚æ•°
        self.point_cloud_enabled = True  # æ˜¯å¦å¯ç”¨ç‚¹äº‘ç”Ÿæˆ
        self.point_cloud_downsample = 5  # ç‚¹äº‘ä¸‹é‡‡æ ·å€æ•°ï¼ˆæ¯nä¸ªåƒç´ å–ä¸€ä¸ªç‚¹ï¼‰
        self.depth_threshold_min = 0.01  # æ·±åº¦æœ€å°é˜ˆå€¼
        self.depth_threshold_max = 1.5   # æ·±åº¦æœ€å¤§é˜ˆå€¼
        self.pointcloud_update_interval = 10  # ç‚¹äº‘æ›´æ–°é—´éš”ï¼ˆå¸§æ•°ï¼‰
        
        # æ§åˆ¶å‚æ•°
        self.angle_step = 5.0       # è§’åº¦è°ƒæ•´æ­¥é•¿ï¼ˆåº¦ï¼‰
        self.fov_step = 5.0         # FOVè°ƒæ•´æ­¥é•¿ï¼ˆåº¦ï¼‰
        self.selected_joint = 0     # å½“å‰é€‰ä¸­çš„å…³èŠ‚
        
        # æœ«ç«¯æ‰§è¡Œå™¨è¿æ†ç´¢å¼•
        self.end_effector_link_index = 7  # link6_1åœ¨URDFä¸­çš„ç´¢å¼•
        
        # è¿è¡Œæ§åˆ¶
        self.running = True
        self.camera_running = False
        self.pointcloud_running = False
        
        # Open3Då¯è§†åŒ–å™¨
        self.vis = None
        self.point_cloud = None
        self.coordinate_frame = None
        
        print("ğŸ“¹ æœºæ¢°è‡‚è™šæ‹Ÿç›¸æœºæ¨¡æ‹Ÿå™¨ï¼ˆé›†æˆä½¿èƒ½è¿‡ç¨‹+ç‚¹äº‘ç”Ÿæˆç‰ˆæœ¬ï¼‰")
        print("=" * 60)
        print("ç›¸æœºå®‰è£…ä½ç½®ï¼šæœ«ç«¯æ³•å…°yè½´æ–¹å‘ï¼ˆç»¿è‰²è½´å‰æ–¹6cmï¼‰")
        print("è§†çº¿æ–¹å‘ï¼šä¸æ³•å…°ç›˜æœå‘å¹³è¡Œ")
        print("åˆå§‹è§†é‡è§’åº¦ï¼š120Â°")
        print("ç‚¹äº‘ç”Ÿæˆï¼šåƒç´ â†’3Dç‚¹â†’Open3Dæ˜¾ç¤ºï¼ˆç®€åŒ–æ€è·¯ï¼‰")
        print("=" * 60)
    
    def start_pybullet(self):
        """å¯åŠ¨PyBulletä»¿çœŸç¯å¢ƒ"""
        # è¿æ¥åˆ°PyBullet GUI
        self.physics_client = p.connect(p.GUI)
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        p.setGravity(0, 0, -9.81)
        p.setPhysicsEngineParameter(enableFileCaching=0)
        
        # åŠ è½½åœ°é¢
        p.loadURDF("plane.urdf", [0, 0, 0])
        
        # åŠ è½½æœºæ¢°è‡‚
        urdf_path = os.path.join(os.path.dirname(os.path.dirname(
            os.path.realpath(__file__))), "dummy2", "dummy2.urdf")
        
        if not os.path.exists(urdf_path):
            print(f"âŒ æ‰¾ä¸åˆ°URDFæ–‡ä»¶: {urdf_path}")
            return False
        
        self.robot_id = p.loadURDF(urdf_path, [0, 0, 0], useFixedBase=True)
        
        # è·å–å…³èŠ‚ä¿¡æ¯
        self.get_joint_info()
        
        # è®¾ç½®ç›¸æœºè§†è§’
        p.resetDebugVisualizerCamera(
            cameraDistance=1.5,
            cameraYaw=45,
            cameraPitch=-30,
            cameraTargetPosition=[0, 0, 0.5]
        )
        
        # æ·»åŠ æµ‹è¯•ç‰©ä½“
        self.add_test_objects()
        
        return True
    
    def get_joint_info(self):
        """è·å–æœºæ¢°è‡‚å…³èŠ‚ä¿¡æ¯"""
        num_joints = p.getNumJoints(self.robot_id)
        self.joint_indices = []
        
        for i in range(num_joints):
            joint_info = p.getJointInfo(self.robot_id, i)
            joint_name = joint_info[1].decode('utf-8')
            
            if joint_name in self.joint_names:
                joint_index = self.joint_names.index(joint_name)
                if joint_index < len(self.joint_indices):
                    self.joint_indices[joint_index] = i
                else:
                    while len(self.joint_indices) <= joint_index:
                        self.joint_indices.append(-1)
                    self.joint_indices[joint_index] = i
    
    def add_test_objects(self):
        """åœ¨ç¯å¢ƒä¸­æ·»åŠ æµ‹è¯•ç‰©ä½“"""
        # åœ¨æœºæ¢°è‡‚å‰æ–¹æ·»åŠ è´§æ¶ç»“æ„
        self.add_shelf_structure()
        
        # æ·»åŠ ä¸€äº›é¢å¤–çš„æµ‹è¯•ç‰©ä½“
        colors = [[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1]]
        positions = [[0.4, 0.4, 0.02], [0.4, -0.4, 0.02], [-0.4, 0.0, 0.02]]
        
        for i, (pos, color) in enumerate(zip(positions, colors)):
            p.createMultiBody(
                baseMass=0.1,
                baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02]),
                baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02], rgbaColor=color),
                basePosition=pos
            )
    
    def add_shelf_structure(self):
        """åœ¨æœºæ¢°è‡‚å‰æ–¹æ·»åŠ è´§æ¶ç»“æ„"""
        # è´§æ¶ä½ç½®ï¼šåœ¨æœºæ¢°è‡‚å‰æ–¹yè½´æ­£æ–¹å‘ï¼Œè·ç¦»çº¦50cm
        shelf_base_pos = [0.0, 0.4, 0.0]
        
        # è´§æ¶é¢œè‰²ï¼šæµ…ç°è‰²
        shelf_color = [0.8, 0.8, 0.8, 1.0]
        
        # è´§æ¶åº•åº§
        shelf_base = p.createMultiBody(
            baseMass=0,  # é™æ€ç‰©ä½“
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.15, 0.05, 0.01]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.15, 0.05, 0.01], rgbaColor=shelf_color),
            basePosition=[shelf_base_pos[0], shelf_base_pos[1], shelf_base_pos[2] + 0.01]
        )
        
        # è´§æ¶å·¦ç«‹æŸ±
        left_column = p.createMultiBody(
            baseMass=0,
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.01, 0.01, 0.2]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.01, 0.01, 0.2], rgbaColor=shelf_color),
            basePosition=[shelf_base_pos[0] - 0.14, shelf_base_pos[1], shelf_base_pos[2] + 0.2]
        )
        
        # è´§æ¶å³ç«‹æŸ±
        right_column = p.createMultiBody(
            baseMass=0,
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.01, 0.01, 0.2]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.01, 0.01, 0.2], rgbaColor=shelf_color),
            basePosition=[shelf_base_pos[0] + 0.14, shelf_base_pos[1], shelf_base_pos[2] + 0.2]
        )
        
        # è´§æ¶ç¬¬ä¸€å±‚æ¿
        shelf_1 = p.createMultiBody(
            baseMass=0,
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.14, 0.04, 0.005]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.14, 0.04, 0.005], rgbaColor=shelf_color),
            basePosition=[shelf_base_pos[0], shelf_base_pos[1], shelf_base_pos[2] + 0.15]
        )
        
        # è´§æ¶ç¬¬äºŒå±‚æ¿
        shelf_2 = p.createMultiBody(
            baseMass=0,
            baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.14, 0.04, 0.005]),
            baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.14, 0.04, 0.005], rgbaColor=shelf_color),
            basePosition=[shelf_base_pos[0], shelf_base_pos[1], shelf_base_pos[2] + 0.3]
        )
        
        # åœ¨è´§æ¶ä¸Šæ”¾ç½®ä¸€äº›ç‰©å“
        # ç¬¬ä¸€å±‚ç‰©å“
        item_colors = [[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1]]
        item_positions = [
            [shelf_base_pos[0] - 0.08, shelf_base_pos[1], shelf_base_pos[2] + 0.17],
            [shelf_base_pos[0], shelf_base_pos[1], shelf_base_pos[2] + 0.17],
            [shelf_base_pos[0] + 0.08, shelf_base_pos[1], shelf_base_pos[2] + 0.17]
        ]
        
        for i, (pos, color) in enumerate(zip(item_positions, item_colors)):
            p.createMultiBody(
                baseMass=0.05,
                baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02]),
                baseVisualShapeIndex=p.createVisualShape(p.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02], rgbaColor=color),
                basePosition=pos
            )
        
        # ç¬¬äºŒå±‚ç‰©å“
        item_positions_2 = [
            [shelf_base_pos[0] - 0.06, shelf_base_pos[1], shelf_base_pos[2] + 0.32],
            [shelf_base_pos[0] + 0.06, shelf_base_pos[1], shelf_base_pos[2] + 0.32]
        ]
        
        for i, pos in enumerate(item_positions_2):
            p.createMultiBody(
                baseMass=0.05,
                baseCollisionShapeIndex=p.createCollisionShape(p.GEOM_CYLINDER, radius=0.02, height=0.04),
                baseVisualShapeIndex=p.createVisualShape(p.GEOM_CYLINDER, radius=0.02, length=0.04, rgbaColor=[1, 1, 0, 1]),
                basePosition=pos
            )
        
        print("âœ… è´§æ¶ç»“æ„æ·»åŠ å®Œæˆ")
        print(f"   è´§æ¶ä½ç½®: {shelf_base_pos}")
        print(f"   è´§æ¶å°ºå¯¸: 30cmÃ—10cmÃ—40cm")
        print(f"   è·ç¦»æœºæ¢°è‡‚: 50cm")
    
    def set_robot_to_disabled_state(self):
        """è®¾ç½®æœºæ¢°è‡‚åˆ°æœªä½¿èƒ½çŠ¶æ€"""
        for i, joint_idx in enumerate(self.joint_indices):
            if joint_idx != -1:
                p.resetJointState(self.robot_id, joint_idx, math.radians(self.disabled_state[i]))
        
        for _ in range(10):
            p.stepSimulation()
            time.sleep(0.001)
    
    def smooth_step(self, t):
        """Sæ›²çº¿æ’å€¼"""
        return t * t * (3.0 - 2.0 * t)
    
    def interpolate_joint_angles(self, start_angles, end_angles, progress):
        """å¹³æ»‘æ’å€¼å…³èŠ‚è§’åº¦"""
        smooth_progress = self.smooth_step(progress)
        return [start + (end - start) * smooth_progress 
                for start, end in zip(start_angles, end_angles)]
    
    def execute_enable_process(self):
        """æ‰§è¡Œä½¿èƒ½è¿‡ç¨‹"""
        print(f"ğŸ”„ ä½¿èƒ½è¿‡ç¨‹: {self.disabled_state} â†’ {self.ready_state}")
        
        start_time = time.time()
        step_duration = self.enable_duration / self.enable_steps
        
        for step in range(self.enable_steps + 1):
            if not self.running:
                break
                
            progress = step / self.enable_steps
            
            # æ’å€¼è®¡ç®—å…³èŠ‚è§’åº¦
            self.current_joint_angles = self.interpolate_joint_angles(
                self.disabled_state, self.ready_state, progress
            )
            
            # æ›´æ–°æœºæ¢°è‡‚å§¿æ€
            self.update_robot_pose()
            p.stepSimulation()
            
            # æ˜¾ç¤ºè¿›åº¦
            if step % 30 == 0 or step == self.enable_steps:
                print(f"è¿›åº¦: {progress*100:5.1f}% - {[f'{a:.1f}Â°' for a in self.current_joint_angles]}")
            
            time.sleep(step_duration)
        
        self.is_enabled = True
        print(f"âœ… ä½¿èƒ½å®Œæˆï¼Œç”¨æ—¶: {time.time() - start_time:.2f}ç§’")
    
    def update_robot_pose(self):
        """æ›´æ–°æœºæ¢°è‡‚çš„å…³èŠ‚è§’åº¦"""
        for i, joint_idx in enumerate(self.joint_indices):
            if joint_idx != -1:
                angle_rad = math.radians(self.current_joint_angles[i])
                p.resetJointState(self.robot_id, joint_idx, angle_rad)
    
    def get_end_effector_pose(self):
        """è·å–æœ«ç«¯æ³•å…°çš„ä½ç½®å’Œå§¿æ€"""
        link_state = p.getLinkState(self.robot_id, self.end_effector_link_index, computeForwardKinematics=True)
        position = list(link_state[0])
        orientation = list(link_state[1])  # å››å…ƒæ•° [x, y, z, w]
        return position, orientation
    
    def calculate_camera_pose(self, flange_position, flange_orientation):
        """åŸºäºæœ«ç«¯æ³•å…°ä½ç½®å’Œå§¿æ€ï¼Œè®¡ç®—ç›¸æœºä½ç½®å’Œå§¿æ€"""
        # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        rotation_matrix = np.array(p.getMatrixFromQuaternion(flange_orientation)).reshape(3, 3)
        
        # ç›¸æœºç›¸å¯¹äºæ³•å…°çš„åç§»å‘é‡ï¼ˆyè½´å‰æ–¹ï¼‰
        camera_offset_local = np.array(self.camera_offset)
        
        # å°†å±€éƒ¨åç§»è½¬æ¢åˆ°å…¨å±€åæ ‡ç³»
        camera_offset_global = rotation_matrix @ camera_offset_local
        
        # è®¡ç®—ç›¸æœºä½ç½®
        camera_position = np.array(flange_position) + camera_offset_global
        
        # ç›¸æœºå§¿æ€ä¸æ³•å…°å§¿æ€ç›¸åŒ
        camera_orientation = flange_orientation
        
        # è®¡ç®—ç›¸æœºæœå‘çš„ç›®æ ‡ç‚¹ï¼ˆæ³•å…°æœå‘å‰æ–¹0.02ç±³å¤„ï¼‰
        forward_direction = rotation_matrix @ np.array([0, 1, 0])  # Yè½´æ­£æ–¹å‘ä¸ºå‰æ–¹
        camera_target = camera_position + forward_direction * 0.02
        
        return camera_position.tolist(), camera_orientation, camera_target.tolist()
    

    def capture_camera_image_with_depth(self, camera_position, camera_target, camera_up=[0, 0, 1]):
        """ä»æŒ‡å®šä½ç½®å’Œæœå‘æ•è·ç›¸æœºå›¾åƒå’Œæ·±åº¦å›¾"""
        # è®¡ç®—è§†å›¾çŸ©é˜µ
        view_matrix = p.computeViewMatrix(
            cameraEyePosition=camera_position,
            cameraTargetPosition=camera_target,
            cameraUpVector=camera_up
        )
        
        # è®¡ç®—æŠ•å½±çŸ©é˜µ
        projection_matrix = p.computeProjectionMatrixFOV(
            fov=self.camera_fov,
            aspect=self.camera_aspect,
            nearVal=self.camera_near,
            farVal=self.camera_far
        )
        
        # æ¸²æŸ“å›¾åƒ
        width, height, rgb_img, depth_img, seg_img = p.getCameraImage(
            width=self.image_width,
            height=self.image_height,
            viewMatrix=view_matrix,
            projectionMatrix=projection_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL
        )
        
        # è½¬æ¢RGBå›¾åƒ - ä¿æŒRGBæ ¼å¼ç”¨äºç‚¹äº‘
        # PyBulletå·²ç»è¿”å›äº†æ­£ç¡®å½¢çŠ¶çš„æ•°ç»„ (height, width, 4)
        rgb_array = np.array(rgb_img, dtype=np.uint8)
        rgb_array = rgb_array[:, :, :3]  # å»æ‰alphaé€šé“ï¼Œä¿æŒRGBé¡ºåº
        
        # ä¸º2Dæ˜¾ç¤ºåˆ›å»ºBGRæ ¼å¼
        bgr_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)
        
        # è½¬æ¢æ·±åº¦å›¾åƒ
        depth_array = np.array(depth_img).reshape(height, width)
        
        # å°†æ·±åº¦ç¼“å†²åŒºå€¼è½¬æ¢ä¸ºå®é™…æ·±åº¦ï¼ˆç±³ï¼‰
        # PyBulletæ·±åº¦ç¼“å†²åŒºä½¿ç”¨éçº¿æ€§æ·±åº¦ï¼Œéœ€è¦è½¬æ¢
        depth_real = self.camera_far * self.camera_near / (self.camera_far - (self.camera_far - self.camera_near) * depth_array)
        
        return bgr_array, rgb_array, depth_real, view_matrix, projection_matrix
    
    def depth_image_to_point_cloud(self, rgb_image, depth_image, camera_position, camera_target, camera_up=[0, 0, 1]):
        """
        å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸ºç‚¹äº‘
        æ ¸å¿ƒæ€è·¯ï¼šæ¯ä¸ªåƒç´  â†’ æ ¹æ®æ·±åº¦å€¼ â†’ 3Dç©ºé—´ä½ç½® + RGBé¢œè‰²
        """
        points = []
        colors = []
        
        height, width = depth_image.shape
        
        # è®¡ç®—ç›¸æœºå†…å‚ï¼ˆä»FOVæ¨å¯¼ç„¦è·ï¼‰
        fov_rad = math.radians(self.camera_fov)
        focal_length = (height / 2.0) / math.tan(fov_rad / 2.0)
        cx, cy = width / 2.0, height / 2.0
        
        # è®¡ç®—ç›¸æœºåæ ‡ç³»åˆ°ä¸–ç•Œåæ ‡ç³»çš„å˜æ¢
        camera_pos = np.array(camera_position)
        target_pos = np.array(camera_target)
        
        # ç›¸æœºåæ ‡ç³»æ–¹å‘å‘é‡
        forward = target_pos - camera_pos
        forward = forward / np.linalg.norm(forward)
        up = np.array([0, 0, 1])
        right = np.cross(forward, up)
        right = right / np.linalg.norm(right)
        up = np.cross(right, forward)
        
        # æ—‹è½¬çŸ©é˜µï¼šç›¸æœºåæ ‡ç³» â†’ ä¸–ç•Œåæ ‡ç³»
        R = np.column_stack([right, -up, forward])
        
        # ä¸‹é‡‡æ ·ä»¥æé«˜æ€§èƒ½ï¼ˆä½¿ç”¨ç±»æˆå‘˜å˜é‡ï¼‰
        step = self.point_cloud_downsample
        
        # éå†åƒç´ ï¼ˆä¸‹é‡‡æ ·ï¼‰
        for v in range(0, height, step):
            for u in range(0, width, step):
                depth = depth_image[v, u]
                
                # ä¸¥æ ¼çš„æ·±åº¦å€¼æ£€æŸ¥
                if (not np.isfinite(depth) or 
                    depth < self.depth_threshold_min or 
                    depth > self.depth_threshold_max or
                    depth <= 0):
                    continue
                
                # åƒç´ åæ ‡ â†’ ç›¸æœºåæ ‡ç³»
                x_cam = (u - cx) * depth / focal_length
                y_cam = (v - cy) * depth / focal_length
                z_cam = depth
                
                # ç›¸æœºåæ ‡ç³» â†’ ä¸–ç•Œåæ ‡ç³»
                point_cam = np.array([x_cam, y_cam, z_cam])
                point_world = camera_pos + R @ point_cam
                
                # æ£€æŸ¥ç”Ÿæˆçš„3Dç‚¹æ˜¯å¦æœ‰æ•ˆ
                if not np.all(np.isfinite(point_world)):
                    continue
                
                # è·å–åƒç´ é¢œè‰²ï¼ˆRGBæ ¼å¼ï¼Œç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼‰
                pixel_color = rgb_image[v, u].astype(np.float32) / 255.0
                pixel_color = np.clip(pixel_color, 0.0, 1.0)  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
                
                # æ£€æŸ¥é¢œè‰²æ˜¯å¦æœ‰æ•ˆ
                if not np.all(np.isfinite(pixel_color)):
                    continue
                
                points.append(point_world)
                colors.append(pixel_color)
        
        if len(points) == 0:
            return np.empty((0, 3)), np.empty((0, 3))
        
        points_array = np.array(points)
        colors_array = np.array(colors)
        
        # æœ€ç»ˆæ•°æ®éªŒè¯
        valid_indices = np.all(np.isfinite(points_array), axis=1) & np.all(np.isfinite(colors_array), axis=1)
        
        return points_array[valid_indices], colors_array[valid_indices]
    
    def capture_camera_image(self, camera_position, camera_target, camera_up=[0, 0, 1]):
        """ä»æŒ‡å®šä½ç½®å’Œæœå‘æ•è·ç›¸æœºå›¾åƒï¼ˆä»…RGBï¼Œç”¨äº2Dæ˜¾ç¤ºï¼‰"""
        # è®¡ç®—è§†å›¾çŸ©é˜µ
        view_matrix = p.computeViewMatrix(
            cameraEyePosition=camera_position,
            cameraTargetPosition=camera_target,
            cameraUpVector=camera_up
        )
        
        # è®¡ç®—æŠ•å½±çŸ©é˜µ
        projection_matrix = p.computeProjectionMatrixFOV(
            fov=self.camera_fov,
            aspect=self.camera_aspect,
            nearVal=self.camera_near,
            farVal=self.camera_far
        )
        
        # æ¸²æŸ“å›¾åƒ
        width, height, rgb_img, depth_img, seg_img = p.getCameraImage(
            width=self.image_width,
            height=self.image_height,
            viewMatrix=view_matrix,
            projectionMatrix=projection_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL
        )
        
        # è½¬æ¢ä¸ºOpenCVæ ¼å¼ï¼ˆBGRï¼‰
        rgb_array = np.array(rgb_img).reshape(height, width, 4)
        rgb_array = rgb_array[:, :, :3]  # å»æ‰alphaé€šé“
        bgr_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)
        
        return bgr_array
    
    def init_open3d_visualizer(self):
        """åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨"""
        # åˆ›å»ºå¯è§†åŒ–å™¨
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window(window_name="å®æ—¶ç‚¹äº‘è§†å›¾", width=1000, height=800)
        
        # åˆ›å»ºç‚¹äº‘å¯¹è±¡
        self.point_cloud = o3d.geometry.PointCloud()
        
        # åˆ›å»ºåæ ‡ç³»
        self.coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)
        
        # æ·»åŠ åˆ°å¯è§†åŒ–å™¨
        self.vis.add_geometry(self.point_cloud)
        self.vis.add_geometry(self.coordinate_frame)
        
        # è·å–æ¸²æŸ“é€‰é¡¹å¹¶ä¼˜åŒ–è®¾ç½®
        render_option = self.vis.get_render_option()
        render_option.point_show_normal = False
        render_option.point_size = 5.0
        render_option.point_color_option = o3d.visualization.PointColorOption.Color
        render_option.light_on = True
        render_option.show_coordinate_frame = True
        render_option.background_color = np.array([0.05, 0.05, 0.05])
        
        # è®¾ç½®è§†è§’
        ctr = self.vis.get_view_control()
        ctr.set_front([0, -1, 0])
        ctr.set_lookat([0, 0, 0.5])
        ctr.set_up([0, 0, 1])
        ctr.set_zoom(0.8)
    
    def update_point_cloud(self, points, colors):
        """æ›´æ–°ç‚¹äº‘æ•°æ®"""
        if self.point_cloud is None or self.vis is None or len(points) == 0:
            return
        
        # ç¡®ä¿ç‚¹å’Œé¢œè‰²æ•°é‡åŒ¹é…
        if len(points) != len(colors):
            min_len = min(len(points), len(colors))
            points = points[:min_len]
            colors = colors[:min_len]
        
        # æ›´æ–°ç‚¹äº‘æ•°æ®
        self.point_cloud.points = o3d.utility.Vector3dVector(points)
        self.point_cloud.colors = o3d.utility.Vector3dVector(colors)
        
        # æ›´æ–°å¯è§†åŒ–
        self.vis.update_geometry(self.point_cloud)
        self.vis.poll_events()
        self.vis.update_renderer()
    
    def pointcloud_thread(self):
        """ç‚¹äº‘ç”Ÿæˆå’Œæ˜¾ç¤ºçº¿ç¨‹"""
        # åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨
        self.init_open3d_visualizer()
        
        frame_count = 0
        last_successful_points = None
        last_successful_colors = None
        
        while self.running and self.pointcloud_running:
            # æ›´æ–°æœºæ¢°è‡‚å§¿æ€
            if frame_count % 2 == 0:
                self.update_robot_pose()
                p.stepSimulation()
            
            # ç”Ÿæˆç‚¹äº‘
            if frame_count % self.pointcloud_update_interval == 0:
                # è·å–æœ«ç«¯æ³•å…°ä½ç½®å’Œå§¿æ€
                flange_position, flange_orientation = self.get_end_effector_pose()
                
                # è®¡ç®—ç›¸æœºä½ç½®å’Œå§¿æ€
                camera_position, camera_orientation, camera_target = self.calculate_camera_pose(
                    flange_position, flange_orientation)
                
                # æ•è·ç›¸æœºå›¾åƒå’Œæ·±åº¦å›¾
                bgr_image, rgb_image, depth_image, view_matrix, projection_matrix = self.capture_camera_image_with_depth(
                    camera_position, camera_target)
                
                # ç”Ÿæˆç‚¹äº‘
                points, colors = self.depth_image_to_point_cloud(
                    rgb_image, depth_image, camera_position, camera_target)
                
                # æ£€æŸ¥ç‚¹äº‘æ˜¯å¦æœ‰æ•ˆ
                if len(points) > 100:
                    last_successful_points = points
                    last_successful_colors = colors
                    
                    # æ›´æ–°Open3Dç‚¹äº‘æ˜¾ç¤º
                    self.update_point_cloud(points, colors)
                    
                elif last_successful_points is not None:
                    # å¦‚æœå½“å‰å¸§ç‚¹äº‘æ— æ•ˆï¼Œä½¿ç”¨ä¸Šä¸€æ¬¡æˆåŠŸçš„ç‚¹äº‘
                    self.update_point_cloud(last_successful_points, last_successful_colors)
            
            # æ›´æ–°Open3Dæ˜¾ç¤º
            self.vis.poll_events()
            self.vis.update_renderer()
            
            frame_count += 1
            time.sleep(0.03)
        
        # å…³é—­Open3Dçª—å£
        if self.vis:
            self.vis.destroy_window()
    
    def camera_thread(self):
        """ç›¸æœºæ˜¾ç¤ºçº¿ç¨‹"""
        cv2.namedWindow('Virtual Camera View', cv2.WINDOW_AUTOSIZE)
        
        while self.running and self.camera_running:
            # æ›´æ–°æœºæ¢°è‡‚å§¿æ€
            self.update_robot_pose()
            p.stepSimulation()
            
            # è·å–æœ«ç«¯æ³•å…°ä½ç½®å’Œå§¿æ€
            flange_position, flange_orientation = self.get_end_effector_pose()
            
            # è®¡ç®—ç›¸æœºä½ç½®å’Œå§¿æ€
            camera_position, camera_orientation, camera_target = self.calculate_camera_pose(
                flange_position, flange_orientation)
            
            # æ•è·ç›¸æœºå›¾åƒ
            camera_image = self.capture_camera_image(camera_position, camera_target)
            
            # åœ¨å›¾åƒä¸Šæ·»åŠ ä¿¡æ¯
            display_image = self.display_info_on_image(camera_image)
            
            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow('Virtual Camera View', display_image)
            cv2.waitKey(1)
            
            time.sleep(0.03)
        
        cv2.destroyAllWindows()
    
    def display_info_on_image(self, image):
        """åœ¨å›¾åƒä¸Šæ˜¾ç¤ºä¿¡æ¯"""
        img_with_info = image.copy()
        
        # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        color = (0, 255, 0)  # ç»¿è‰²
        thickness = 2
        
        # æ˜¾ç¤ºç›¸æœºå‚æ•°å’ŒçŠ¶æ€
        info_lines = [
            f"çŠ¶æ€: {'å·²ä½¿èƒ½' if self.is_enabled else 'æœªä½¿èƒ½'}",
            f"FOV: {self.camera_fov:.1f}Â°",
            f"é€‰ä¸­å…³èŠ‚: J{self.selected_joint + 1}",
            f"å…³èŠ‚è§’åº¦: {[f'{a:.1f}Â°' for a in self.current_joint_angles]}"
        ]
        
        y_offset = 30
        for i, line in enumerate(info_lines):
            cv2.putText(img_with_info, line, (10, y_offset + i * 25), 
                       font, font_scale, color, thickness)
        
        # æ˜¾ç¤ºæ§åˆ¶è¯´æ˜
        control_info = [
            "ç»ˆç«¯æ§åˆ¶å‘½ä»¤:",
            "joint <1-6>: é€‰æ‹©å…³èŠ‚",
            "up/down: å…³èŠ‚è§’åº¦ +/-",
            "fov <angle>: è®¾ç½®è§†é‡è§’åº¦",
            "downsample <å€æ•°>: è®¾ç½®ç‚¹äº‘ä¸‹é‡‡æ ·å€æ•°",
            "toggle_pointcloud: å¼€å¯/å…³é—­ç‚¹äº‘ç”Ÿæˆ",
            "reset: é‡ç½®åˆ°ä½¿èƒ½çŠ¶æ€",
            "quit: é€€å‡ºç¨‹åº"
        ]
        
        y_start = img_with_info.shape[0] - len(control_info) * 20 - 10
        for i, line in enumerate(control_info):
            cv2.putText(img_with_info, line, (10, y_start + i * 18), 
                       font, 0.4, (255, 255, 0), 1)  # é’è‰²å°å­—
        
        return img_with_info
    
    def handle_terminal_input(self, command):
        """å¤„ç†ç»ˆç«¯è¾“å…¥å‘½ä»¤"""
        command = command.strip().lower()
        
        if command == 'quit' or command == 'exit':
            return False
        
        elif command.startswith('joint '):
            joint_num = int(command.split()[1])
            if 1 <= joint_num <= 6:
                self.selected_joint = joint_num - 1
                print(f"ğŸ¯ é€‰ä¸­å…³èŠ‚ J{joint_num}")
            else:
                print("âŒ å…³èŠ‚ç¼–å·å¿…é¡»åœ¨1-6ä¹‹é—´")
        
        elif command == 'up':
            if self.is_enabled:
                self.current_joint_angles[self.selected_joint] += self.angle_step
                print(f"â¬†ï¸ J{self.selected_joint + 1}: {self.current_joint_angles[self.selected_joint]:.1f}Â°")
            else:
                print("âŒ è¯·å…ˆå®Œæˆä½¿èƒ½è¿‡ç¨‹")
        
        elif command == 'down':
            if self.is_enabled:
                self.current_joint_angles[self.selected_joint] -= self.angle_step
                print(f"â¬‡ï¸ J{self.selected_joint + 1}: {self.current_joint_angles[self.selected_joint]:.1f}Â°")
            else:
                print("âŒ è¯·å…ˆå®Œæˆä½¿èƒ½è¿‡ç¨‹")
        
        elif command.startswith('fov '):
            fov_value = float(command.split()[1])
            if 10.0 <= fov_value <= 180.0:
                self.camera_fov = fov_value
                print(f"ğŸ” FOVè®¾ç½®ä¸º: {self.camera_fov:.1f}Â°")
            else:
                print("âŒ FOVå¿…é¡»åœ¨10-180åº¦ä¹‹é—´")
        
        elif command.startswith('downsample '):
            downsample_value = int(command.split()[1])
            if 1 <= downsample_value <= 20:
                self.point_cloud_downsample = downsample_value
                print(f"ğŸ”½ ç‚¹äº‘ä¸‹é‡‡æ ·è®¾ç½®ä¸º: {self.point_cloud_downsample}")
            else:
                print("âŒ ä¸‹é‡‡æ ·å€æ•°å¿…é¡»åœ¨1-20ä¹‹é—´")
        
        elif command == 'toggle_pointcloud':
            self.point_cloud_enabled = not self.point_cloud_enabled
            print(f"ğŸ¨ ç‚¹äº‘ç”Ÿæˆ: {'å¼€å¯' if self.point_cloud_enabled else 'å…³é—­'}")
        
        elif command.startswith('interval '):
            interval_value = int(command.split()[1])
            if 1 <= interval_value <= 60:
                self.pointcloud_update_interval = interval_value
                print(f"â±ï¸ ç‚¹äº‘æ›´æ–°é—´éš”è®¾ç½®ä¸º: {self.pointcloud_update_interval} å¸§")
            else:
                print("âŒ æ›´æ–°é—´éš”å¿…é¡»åœ¨1-60å¸§ä¹‹é—´")
        
        elif command.startswith('pointsize '):
            point_size = float(command.split()[1])
            if 1.0 <= point_size <= 20.0:
                if self.vis:
                    render_option = self.vis.get_render_option()
                    render_option.point_size = point_size
                    print(f"ğŸ” ç‚¹äº‘å¤§å°è®¾ç½®ä¸º: {point_size}")
                else:
                    print("âŒ ç‚¹äº‘å¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")
            else:
                print("âŒ ç‚¹å¤§å°å¿…é¡»åœ¨1.0-20.0ä¹‹é—´")
        
        elif command.startswith('depth_range '):
            parts = command.split()
            if len(parts) == 3:
                min_depth = float(parts[1])
                max_depth = float(parts[2])
                if 0.001 <= min_depth < max_depth <= 5.0:
                    self.depth_threshold_min = min_depth
                    self.depth_threshold_max = max_depth
                    print(f"ğŸ“ æ·±åº¦èŒƒå›´è®¾ç½®ä¸º: {min_depth:.3f}m - {max_depth:.3f}m")
                else:
                    print("âŒ æ·±åº¦èŒƒå›´å¿…é¡»: 0.001 <= min < max <= 5.0")
            else:
                print("âŒ ç”¨æ³•: depth_range <æœ€å°æ·±åº¦> <æœ€å¤§æ·±åº¦>")
        
        elif command == 'reset':
            if self.is_enabled:
                self.current_joint_angles = self.ready_state.copy()
                print("ğŸ”„ é‡ç½®åˆ°ä½¿èƒ½çŠ¶æ€")
            else:
                print("âŒ è¯·å…ˆå®Œæˆä½¿èƒ½è¿‡ç¨‹")
        
        elif command == 'status':
            print(f"ğŸ“Š å½“å‰çŠ¶æ€:")
            print(f"   ä½¿èƒ½çŠ¶æ€: {'æ˜¯' if self.is_enabled else 'å¦'}")
            print(f"   é€‰ä¸­å…³èŠ‚: J{self.selected_joint + 1}")
            print(f"   å…³èŠ‚è§’åº¦: {[f'{a:.1f}Â°' for a in self.current_joint_angles]}")
            print(f"   ç›¸æœºFOV: {self.camera_fov:.1f}Â°")
            print(f"   ç‚¹äº‘ç”Ÿæˆ: {'å¼€å¯' if self.point_cloud_enabled else 'å…³é—­'}")
        
        elif command == 'help':
            print("ğŸ“– å¯ç”¨å‘½ä»¤:")
            print("   joint <1-6>      - é€‰æ‹©å…³èŠ‚")
            print("   up               - å¢åŠ é€‰ä¸­å…³èŠ‚è§’åº¦")
            print("   down             - å‡å°‘é€‰ä¸­å…³èŠ‚è§’åº¦")
            print("   fov <è§’åº¦>       - è®¾ç½®ç›¸æœºè§†é‡è§’åº¦")
            print("   downsample <å€æ•°> - è®¾ç½®ç‚¹äº‘ä¸‹é‡‡æ ·å€æ•°(1-20)")
            print("   interval <å¸§æ•°>   - è®¾ç½®ç‚¹äº‘æ›´æ–°é—´éš”(1-60)")
            print("   pointsize <å¤§å°>  - è®¾ç½®ç‚¹äº‘ç‚¹å¤§å°(1.0-20.0)")
            print("   depth_range <min> <max> - è®¾ç½®æ·±åº¦èŒƒå›´")
            print("   toggle_pointcloud - å¼€å¯/å…³é—­ç‚¹äº‘ç”Ÿæˆ")
            print("   reset            - é‡ç½®åˆ°ä½¿èƒ½çŠ¶æ€")
            print("   status           - æ˜¾ç¤ºå½“å‰çŠ¶æ€")
            print("   help             - æ˜¾ç¤ºå¸®åŠ©")
            print("   quit             - é€€å‡ºç¨‹åº")
        
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            print("è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        
        return True
    
    def run_simulation(self):
        """è¿è¡Œä¸»æ¨¡æ‹Ÿå¾ªç¯"""
        print("\nğŸš€ å¯åŠ¨è™šæ‹Ÿç›¸æœºæ¨¡æ‹Ÿå™¨...")
        print("=" * 60)
        
        # è®¾ç½®åˆå§‹çŠ¶æ€
        self.set_robot_to_disabled_state()
        print(f"æœªä½¿èƒ½çŠ¶æ€: {self.disabled_state}")
        print(f"ç›®æ ‡ä½¿èƒ½çŠ¶æ€: {self.ready_state}")
        
        # è¯¢é—®æ˜¯å¦å¼€å§‹ä½¿èƒ½
        input("æŒ‰ Enter å¼€å§‹ä½¿èƒ½è¿‡ç¨‹...")
        
        # æ‰§è¡Œä½¿èƒ½è¿‡ç¨‹
        self.execute_enable_process()
        
        if not self.running:
            return
        
        # å¯åŠ¨ç›¸æœºæ˜¾ç¤º
        print("\nğŸ“¹ å¯åŠ¨è™šæ‹Ÿç›¸æœº...")
        self.camera_running = True
        camera_thread = threading.Thread(target=self.camera_thread)
        camera_thread.daemon = True
        camera_thread.start()
        
        # å¯åŠ¨ç‚¹äº‘ç”Ÿæˆ
        if self.point_cloud_enabled:
            print("\nğŸ¨ å¯åŠ¨ç‚¹äº‘ç”Ÿæˆ...")
            self.pointcloud_running = True
            pointcloud_thread = threading.Thread(target=self.pointcloud_thread)
            pointcloud_thread.daemon = True
            pointcloud_thread.start()
        
        # ç»ˆç«¯äº¤äº’å¾ªç¯
        print("\nğŸ’¬ ç»ˆç«¯äº¤äº’æ¨¡å¼å¯åŠ¨")
        print("è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ï¼Œè¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
        print("=" * 60)
        
        while self.running:
            command = input("è¯·è¾“å…¥å‘½ä»¤: ")
            if not self.handle_terminal_input(command):
                break
        
        print("ğŸ”š ç¨‹åºç»“æŸ")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.running = False
        self.camera_running = False
        self.pointcloud_running = False
        
        if self.physics_client is not None:
            p.disconnect()

def main():
    """ä¸»å‡½æ•°"""
    simulator = VirtualCameraWithPointCloud()
    
    # å¯åŠ¨PyBulletç¯å¢ƒ
    if not simulator.start_pybullet():
        return
    
    # è¿è¡Œä»¿çœŸ
    simulator.run_simulation()
    
    # æ¸…ç†èµ„æº
    simulator.cleanup()

if __name__ == "__main__":
    main() 