import os
import sys
import warnings
import json
import socket
import time
import numpy as np
import cv2
import open3d as o3d

# å®Œå…¨ç¦ç”¨æ‰€æœ‰è­¦å‘Š
warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore'

# ç¦ç”¨ç‰¹å®šçš„FutureWarning
warnings.filterwarnings('ignore', category=FutureWarning, module='torch.cuda.amp.autocast')
warnings.filterwarnings('ignore', category=FutureWarning, module='torch.amp.autocast')

code_dir = os.path.dirname(os.path.realpath(__file__))
sys.path.append(f'{code_dir}/../')
import argparse
import threading
import queue
import time
from queue import Queue
import pyrealsense2 as rs
from dataclasses import dataclass

@dataclass
class BBoxInfo:
    x1: int
    y1: int
    x2: int
    y2: int
    active: bool = True

class RMJointRobotController:
    def __init__(self, ip, port=8080):
        self.ip = ip
        self.port = port
        self.sock = None
        
    def connect(self):
        """å»ºç«‹TCPè¿æ¥"""
        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.settimeout(10)  # è®¾ç½®10ç§’è¶…æ—¶
            self.sock.connect((self.ip, self.port))
            print(f"æˆåŠŸè¿æ¥åˆ°æœºæ¢°è‡‚ {self.ip}:{self.port}")
            return True
        except Exception as e:
            print(f"è¿æ¥å¤±è´¥: {e}")
            return False
    
    def send_command(self, command_dict, wait_response=True):
        """å‘é€JSONæŒ‡ä»¤åˆ°æœºæ¢°è‡‚"""
        if not self.sock:
            print("é”™è¯¯ï¼šæœªå»ºç«‹è¿æ¥")
            return None
            
        try:
            json_str = json.dumps(command_dict, separators=(',', ':'))
            full_command = json_str + "\r\n"
            
            self.sock.sendall(full_command.encode('utf-8'))
            
            if wait_response:
                response = self.sock.recv(1024).decode('utf-8').strip()
                return json.loads(response)
            return None
            
        except socket.timeout:
            print("è­¦å‘Šï¼šæ¥æ”¶å“åº”è¶…æ—¶")
            return None
        except Exception as e:
            print(f"å‘é€æŒ‡ä»¤æ—¶å‡ºé”™: {e}")
            return None

class StereoCamera:
    def __init__(self):
        self.pipeline = None
        self.config = None
        self.align = None  # ç”¨äºå¯¹é½æ·±åº¦å’ŒRGBå›¾åƒ
        self.fps = 10
        self.frame_time = 1.0 / self.fps
        
        # RealSenseç‚¹äº‘å¯¹è±¡
        self.pc = rs.pointcloud()
        self.depth_scale = None
        
        # çº¿ç¨‹æ§åˆ¶
        self.is_running = False
        self.capture_thread = None
        self.process_thread = None
        
        # é˜Ÿåˆ—
        self.frame_queue = Queue(maxsize=1)
        self.display_queue = Queue(maxsize=1)
        
        # æ¡†é€‰çŠ¶æ€
        self.bbox = None
        self.drawing = False
        self.start_point = None
        self.end_point = None
        
        # çº¿ç¨‹é”
        self.lock = threading.Lock()

    @staticmethod
    def check_camera_availability():
        """æ£€æŸ¥RealSenseç›¸æœºæ˜¯å¦å¯ç”¨"""
        try:
            ctx = rs.context()
            devices = ctx.query_devices()
            if len(devices) == 0:
                print("âŒ æœªæ£€æµ‹åˆ°RealSenseè®¾å¤‡")
                return False
            
            # å°è¯•ç®€å•çš„è¿æ¥æµ‹è¯•
            test_pipeline = rs.pipeline()
            test_config = rs.config()
            test_config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            
            try:
                test_pipeline.start(test_config)
                # å°è¯•è·å–ä¸€å¸§æ•°æ®
                frames = test_pipeline.wait_for_frames(timeout_ms=5000)
                test_pipeline.stop()
                print("âœ… ç›¸æœºå¯ç”¨æ€§æµ‹è¯•é€šè¿‡")
                return True
            except Exception as e:
                print(f"âŒ ç›¸æœºè¢«å ç”¨æˆ–ä¸å¯ç”¨: {e}")
                try:
                    test_pipeline.stop()
                except:
                    pass
                return False
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç›¸æœºå¯ç”¨æ€§æ—¶å‡ºé”™: {e}")
            return False

    def set_fps(self, fps: int):
        """è®¾ç½®å¸§ç‡"""
        self.fps = fps
        self.frame_time = 1.0 / self.fps

    def mouse_callback(self, event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
            self.start_point = (x, y)
        elif event == cv2.EVENT_MOUSEMOVE and self.drawing:
            self.end_point = (x, y)
        elif event == cv2.EVENT_LBUTTONUP:
            self.drawing = False
            if self.start_point and (x, y):
                x1, y1 = self.start_point
                x2, y2 = x, y
                # ç¡®ä¿åæ ‡ä¸ºæ­£
                x1, x2 = min(x1, x2), max(x1, x2)
                y1, y2 = min(y1, y2), max(y1, y2)
                self.bbox = BBoxInfo(x1, y1, x2, y2)
                print(f"æ¡†é€‰åŒºåŸŸåæ ‡: ({x1}, {y1}), ({x2}, {y2})")

    def init_realsense(self):
        """åˆå§‹åŒ–RealSenseç›¸æœº"""
        try:
            # å…ˆå°è¯•è·å–å¯ç”¨è®¾å¤‡
            ctx = rs.context()
            devices = ctx.query_devices()
            if len(devices) == 0:
                print("âŒ æœªæ£€æµ‹åˆ°RealSenseè®¾å¤‡")
                return False
            
            device = devices[0]
            print(f"âœ… æ£€æµ‹åˆ°è®¾å¤‡: {device.get_info(rs.camera_info.name)}")
            
            self.pipeline = rs.pipeline()
            self.config = rs.config()
            
            # é…ç½®æ·±åº¦å’ŒRGBæµï¼ˆç¡®ä¿å®Œç¾å¯¹é½ï¼‰
            self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            
            # å¯åŠ¨ç®¡é“
            profile = self.pipeline.start(self.config)
            
            # è·å–æ·±åº¦ä¼ æ„Ÿå™¨å¹¶é…ç½®
            depth_sensor = profile.get_device().first_depth_sensor()
            self.depth_scale = depth_sensor.get_depth_scale()
            print(f"ğŸ“ æ·±åº¦å•ä½: {self.depth_scale:.6f} ç±³/å•ä½")
            
            # ä¼˜åŒ–æ·±åº¦ä¼ æ„Ÿå™¨è®¾ç½®
            if depth_sensor.supports(rs.option.visual_preset):
                try:
                    # è®¾ç½®ä¸ºé«˜ç²¾åº¦æ¨¡å¼
                    depth_sensor.set_option(rs.option.visual_preset, 4)  # High Accuracy preset
                    print("ğŸ¯ å·²è®¾ç½®é«˜ç²¾åº¦æ¨¡å¼")
                except:
                    try:
                        depth_sensor.set_option(rs.option.visual_preset, 3)  # High Density preset
                        print("ğŸ¯ å·²è®¾ç½®é«˜å¯†åº¦æ¨¡å¼")
                    except:
                        print("âš ï¸ æ— æ³•è®¾ç½®è§†è§‰é¢„è®¾ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
            
            if depth_sensor.supports(rs.option.laser_power):
                # è®¾ç½®æ¿€å…‰åŠŸç‡ä¸ºæœ€å¤§
                depth_sensor.set_option(rs.option.laser_power, 240)
                print("ğŸ”† å·²è®¾ç½®æœ€å¤§æ¿€å…‰åŠŸç‡")
            
            # åˆ›å»ºå¯¹é½å¯¹è±¡ï¼šå°†æ·±åº¦å›¾å¯¹é½åˆ°RGBå›¾åƒåæ ‡ç³»
            self.align = rs.align(rs.stream.color)
            
            # è®¾ç½®åå¤„ç†æ»¤æ³¢å™¨ï¼ˆæé«˜ç‚¹äº‘è´¨é‡ï¼‰
            self.setup_post_processing_filters()
            
            # ç­‰å¾…å‡ å¸§ä»¥ç¡®ä¿ç›¸æœºç¨³å®š
            print("ğŸ“· ç­‰å¾…ç›¸æœºç¨³å®š...")
            for i in range(10):
                try:
                    frames = self.pipeline.wait_for_frames(timeout_ms=5000)
                    if frames:
                        print(f"ç¬¬{i+1}/10å¸§ç¨³å®šæµ‹è¯•æˆåŠŸ")
                        break
                except RuntimeError as e:
                    print(f"ç¬¬{i+1}/10å¸§ç¨³å®šæµ‹è¯•å¤±è´¥: {e}")
                    if i == 9:  # æœ€åä¸€æ¬¡å°è¯•
                        raise e
                    time.sleep(0.1)
            
            print("âœ… RealSense D435i (æ·±åº¦+RGBæ¨¡å¼) åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ RealSenseåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            if self.pipeline:
                try:
                    self.pipeline.stop()
                except:
                    pass
            return False

    def setup_post_processing_filters(self):
        """è®¾ç½®åå¤„ç†æ»¤æ³¢å™¨é“¾"""
        try:
            # 1. è§†å·®å˜æ¢æ»¤æ³¢å™¨
            self.disparity_to_depth = rs.disparity_transform(True)
            self.depth_to_disparity = rs.disparity_transform(False)
            
            # 2. ç©ºé—´æ»¤æ³¢å™¨ - å‡å°‘å™ªç‚¹ï¼Œä¿æŒè¾¹ç¼˜
            self.spatial_filter = rs.spatial_filter()
            self.spatial_filter.set_option(rs.option.filter_magnitude, 2)
            self.spatial_filter.set_option(rs.option.filter_smooth_alpha, 0.5)
            self.spatial_filter.set_option(rs.option.filter_smooth_delta, 20)
            
            # 3. æ—¶åºæ»¤æ³¢å™¨ - åˆ©ç”¨å¸§é—´ä¿¡æ¯å‡å°‘æ—¶é—´å™ªå£°
            self.temporal_filter = rs.temporal_filter()
            self.temporal_filter.set_option(rs.option.filter_smooth_alpha, 0.4)
            self.temporal_filter.set_option(rs.option.filter_smooth_delta, 20)
            
            # 4. å­”å¡«å……æ»¤æ³¢å™¨
            self.hole_filling = rs.hole_filling_filter()
            
            # æ»¤æ³¢å™¨é“¾
            self.filters = [
                self.disparity_to_depth,
                self.spatial_filter,
                self.temporal_filter,
                self.depth_to_disparity,
                self.hole_filling
            ]
            
            print(f"ğŸ”§ åå¤„ç†æ»¤æ³¢å™¨é“¾: {len(self.filters)} ä¸ªæ»¤æ³¢å™¨")
            
        except Exception as e:
            print(f"âš ï¸ æ»¤æ³¢å™¨è®¾ç½®å¤±è´¥: {e}")
            self.filters = []

    def apply_filters(self, depth_frame):
        """åº”ç”¨åå¤„ç†æ»¤æ³¢å™¨é“¾"""
        if not hasattr(self, 'filters') or not self.filters:
            return depth_frame
        
        filtered_frame = depth_frame
        for filter_obj in self.filters:
            try:
                filtered_frame = filter_obj.process(filtered_frame)
            except:
                continue
        
        return filtered_frame

    def capture_frames(self):
        """å›¾åƒé‡‡é›†çº¿ç¨‹"""
        if not self.init_realsense():
            print("æ— æ³•å¯åŠ¨RealSenseç›¸æœº")
            self.is_running = False
            return

        consecutive_failures = 0
        max_consecutive_failures = 5
        
        while self.is_running:
            try:
                # ä½¿ç”¨è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´å¹¶å¤„ç†è¶…æ—¶å¼‚å¸¸
                frames = self.pipeline.wait_for_frames(timeout_ms=10000)
                
                # é‡ç½®å¤±è´¥è®¡æ•°å™¨
                consecutive_failures = 0
                
                # å¯¹é½æ·±åº¦å›¾åˆ°RGBå›¾åƒåæ ‡ç³»
                aligned_frames = self.align.process(frames)
                
                # è·å–å¯¹é½åçš„æ·±åº¦å›¾å’ŒRGBå›¾åƒ
                depth_frame = aligned_frames.get_depth_frame()
                color_frame = aligned_frames.get_color_frame()
                
                if not depth_frame or not color_frame:
                    print("âš ï¸ æœªè·å–åˆ°æ·±åº¦å¸§æˆ–RGBå¸§")
                    continue
                
                # åº”ç”¨åå¤„ç†æ»¤æ³¢å™¨æé«˜æ·±åº¦å›¾è´¨é‡
                filtered_depth_frame = self.apply_filters(depth_frame)
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                rgb_image = np.asanyarray(color_frame.get_data())

                try:
                    # ä¼ é€’æ·±åº¦å¸§å’ŒRGBå›¾åƒç”¨äºç‚¹äº‘è®¡ç®—
                    self.frame_queue.put_nowait((filtered_depth_frame, color_frame, rgb_image.copy(), self.bbox))
                except queue.Full:
                    try:
                        self.frame_queue.get_nowait()
                        self.frame_queue.put_nowait((filtered_depth_frame, color_frame, rgb_image.copy(), self.bbox))
                    except queue.Empty:
                        pass

            except RuntimeError as e:
                error_msg = str(e)
                consecutive_failures += 1
                
                if "Frame didn't arrive within" in error_msg:
                    print(f"âš ï¸ å¸§æ¥æ”¶è¶…æ—¶ ({consecutive_failures}/{max_consecutive_failures}): {error_msg}")
                elif "Frame was corrupted" in error_msg:
                    print(f"âš ï¸ å¸§æŸå ({consecutive_failures}/{max_consecutive_failures}): {error_msg}")
                else:
                    print(f"âš ï¸ é‡‡é›†å¸§æ—¶å‡ºé”™ ({consecutive_failures}/{max_consecutive_failures}): {error_msg}")
                
                # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–ç›¸æœº
                if consecutive_failures >= max_consecutive_failures:
                    print("ğŸ”„ è¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–ç›¸æœº...")
                    self.release()
                    time.sleep(1)
                    if self.init_realsense():
                        consecutive_failures = 0
                        print("âœ… ç›¸æœºé‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                    else:
                        print("âŒ ç›¸æœºé‡æ–°åˆå§‹åŒ–å¤±è´¥ï¼Œåœæ­¢é‡‡é›†")
                        self.is_running = False
                        break
                else:
                    # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    time.sleep(0.1)
                    
            except Exception as e:
                consecutive_failures += 1
                print(f"âš ï¸ é‡‡é›†å¸§æ—¶å‡ºç°æœªçŸ¥é”™è¯¯ ({consecutive_failures}/{max_consecutive_failures}): {str(e)}")
                
                if consecutive_failures >= max_consecutive_failures:
                    print("âŒ é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢é‡‡é›†")
                    self.is_running = False
                    break
                else:
                    time.sleep(0.1)

    def process_frames(self, model, args):
        """å›¾åƒå¤„ç†çº¿ç¨‹ - ä½¿ç”¨RealSenseå†…ç½®ç‚¹äº‘ç”Ÿæˆ"""
        while self.is_running:
            try:
                depth_frame, color_frame, rgb_img, bbox = self.frame_queue.get(timeout=0.1)
            except queue.Empty:
                continue

            try:
                # ä½¿ç”¨RealSenseå†…ç½®çš„é«˜æ•ˆç‚¹äº‘ç”Ÿæˆç®—æ³•
                # è¿™æ ·å¯ä»¥ç¡®ä¿RGBé¢œè‰²ä¸3Dåæ ‡å®Œç¾å¯¹åº”
                
                # è®¾ç½®ç‚¹äº‘çš„çº¹ç†æ˜ å°„
                self.pc.map_to(color_frame)
                
                # è®¡ç®—ç‚¹äº‘
                points = self.pc.calculate(depth_frame)
                
                # è·å–é¡¶ç‚¹åæ ‡ï¼ˆ3Dä½ç½®ï¼‰
                vertices = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)
                
                # è·å–çº¹ç†åæ ‡ç”¨äºé¢œè‰²æ˜ å°„
                tex_coords = np.asanyarray(points.get_texture_coordinates()).view(np.float32).reshape(-1, 2)
                
                # ä»RGBå›¾åƒä¸­æå–é¢œè‰²
                h, w = rgb_img.shape[:2]
                
                # æ‰¹é‡å¤„ç†çº¹ç†åæ ‡ä»¥è·å–é¢œè‰²
                u_coords = np.clip((tex_coords[:, 0] * w).astype(np.int32), 0, w-1)
                v_coords = np.clip((tex_coords[:, 1] * h).astype(np.int32), 0, h-1)
                
                # å‘é‡åŒ–é¢œè‰²æå–ï¼ˆBGRè½¬RGBå¹¶å½’ä¸€åŒ–ï¼‰
                colors = rgb_img[v_coords, u_coords]  # BGRæ ¼å¼
                colors = colors[:, [2, 1, 0]] / 255.0  # è½¬æ¢ä¸ºRGBå¹¶å½’ä¸€åŒ–
                
                # åˆ›å»ºOpen3Dç‚¹äº‘
                pcd = o3d.geometry.PointCloud()
                pcd.points = o3d.utility.Vector3dVector(vertices)
                pcd.colors = o3d.utility.Vector3dVector(colors)
                
                # è¿‡æ»¤ç‚¹äº‘ï¼šç§»é™¤æ— æ•ˆç‚¹å’Œè¿œè·ç¦»ç‚¹
                points_array = np.asarray(pcd.points)
                colors_array = np.asarray(pcd.colors)
                
                # è®¡ç®—è·ç¦»å¹¶è¿‡æ»¤
                distances = np.linalg.norm(points_array, axis=1)
                valid_mask = (distances > 0.2) & (distances < args.z_far) & (distances > 0)
                
                if np.sum(valid_mask) > 0:
                    pcd.points = o3d.utility.Vector3dVector(points_array[valid_mask])
                    pcd.colors = o3d.utility.Vector3dVector(colors_array[valid_mask])
                
                # å¯é€‰ï¼šç»Ÿè®¡æ»¤æ³¢å»é™¤ç¦»ç¾¤ç‚¹
                if args.denoise_cloud and len(pcd.points) > 1000:
                    pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=args.denoise_nb_points, std_ratio=2.0)
                
                # å¤„ç†bboxåŒºåŸŸæ ‡è®°
                if bbox and bbox.active:
                    # ç”±äºæ·±åº¦å›¾å’ŒRGBå›¾å·²ç»å¯¹é½ï¼Œbboxåæ ‡å¯ä»¥ç›´æ¥ä½¿ç”¨
                    x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2
                    
                    # ä¿å­˜æ ‡è®°åçš„RGBå›¾åƒ
                    marked_img = rgb_img.copy()
                    cv2.rectangle(marked_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                    os.makedirs('static', exist_ok=True)
                    cv2.imwrite('static/marked_rgb_image.jpg', marked_img)
                    
                    # æ ‡è®°ç‚¹äº‘ä¸­bboxåŒºåŸŸçš„ç‚¹ä¸ºçº¢è‰²
                    # ç”±äºRGBå’Œæ·±åº¦å·²ç»å¯¹é½ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨åƒç´ åæ ‡æ¥æ ‡è®°ç‚¹äº‘
                    
                    # è·å–æ·±åº¦å›¾æ•°ç»„
                    depth_image = np.asanyarray(depth_frame.get_data())
                    
                    # åˆ›å»ºbboxåŒºåŸŸçš„æ©ç 
                    bbox_mask = np.zeros_like(depth_image, dtype=bool)
                    bbox_mask[y1:y2, x1:x2] = True
                    
                    # å°†æ©ç è½¬æ¢ä¸ºç‚¹äº‘ç´¢å¼•
                    # ç”±äºç‚¹äº‘æ˜¯æŒ‰ç…§å›¾åƒçš„è¡Œåˆ—é¡ºåºæ’åˆ—çš„ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å¯¹åº”çš„ç´¢å¼•
                    bbox_indices = []
                    for y in range(y1, min(y2, h)):
                        for x in range(x1, min(x2, w)):
                            if depth_image[y, x] > 0:  # åªå¤„ç†æœ‰æ•ˆæ·±åº¦çš„ç‚¹
                                idx = y * w + x
                                if idx < len(vertices) and valid_mask[idx]:
                                    # æ‰¾åˆ°è¿‡æ»¤åç‚¹äº‘ä¸­çš„å¯¹åº”ç´¢å¼•
                                    original_idx = np.where(valid_mask)[0]
                                    filtered_idx = np.where(original_idx == idx)[0]
                                    if len(filtered_idx) > 0:
                                        bbox_indices.append(filtered_idx[0])
                    
                    # å°†bboxåŒºåŸŸå†…çš„ç‚¹æ ‡è®°ä¸ºçº¢è‰²
                    if bbox_indices:
                        colors_array = np.asarray(pcd.colors)
                        colors_array[bbox_indices] = [1, 0, 0]  # çº¢è‰²
                        pcd.colors = o3d.utility.Vector3dVector(colors_array)
                        
                        # è®¡ç®—bboxåŒºåŸŸå†…ç‚¹çš„ä¸­å¿ƒåæ ‡
                        bbox_points = np.asarray(pcd.points)[bbox_indices]
                        if len(bbox_points) > 0:
                            center_point = np.mean(bbox_points, axis=0)
                            print(f"\nğŸ¯ ç›®æ ‡ç‰©ä½“ä¸­å¿ƒåæ ‡ (ç±³):")
                            print(f"   X={center_point[0]:.3f}, Y={center_point[1]:.3f}, Z={center_point[2]:.3f}")
                            print(f"   æ ‡è®°ç‚¹æ•°: {len(bbox_points)}")

                try:
                    self.display_queue.put_nowait(pcd)
                except queue.Full:
                    try:
                        self.display_queue.get_nowait()
                        self.display_queue.put_nowait(pcd)
                    except queue.Empty:
                        pass
                        
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å¸§æ—¶å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()

    def get_display_frame(self):
        """è·å–æœ€æ–°çš„æ˜¾ç¤ºå¸§ä½†ä¸åˆ é™¤é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
        try:
            with self.lock:
                if self.frame_queue.empty() or self.display_queue.empty():
                    return None
                    
                if not self.frame_queue.empty() and not self.display_queue.empty():
                    frame_data = self.frame_queue.queue[0]
                    depth_frame, color_frame, rgb_img, _ = frame_data
                    pcd = self.display_queue.queue[0]
                    return depth_frame, color_frame, rgb_img, pcd
                return None
                
        except Exception as e:
            print(f"è·å–æ˜¾ç¤ºå¸§æ—¶å‡ºé”™: {str(e)}")
            return None

    def start_processing(self, model, args):
        """å¯åŠ¨æ‰€æœ‰å¤„ç†çº¿ç¨‹"""
        self.is_running = True
        
        # å¯åŠ¨é‡‡é›†çº¿ç¨‹
        self.capture_thread = threading.Thread(target=self.capture_frames)
        self.capture_thread.daemon = True
        self.capture_thread.start()
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.process_thread = threading.Thread(target=self.process_frames, args=(model, args))
        self.process_thread.daemon = True
        self.process_thread.start()

    def stop_processing(self):
        """åœæ­¢æ‰€æœ‰å¤„ç†çº¿ç¨‹"""
        self.is_running = False
        
        if self.capture_thread:
            self.capture_thread.join(timeout=1.0)
        if self.process_thread:
            self.process_thread.join(timeout=1.0)
            
        self.release()

    def release(self):
        """é‡Šæ”¾èµ„æº"""
        try:
            if self.pipeline is not None:
                print("ğŸ”„ æ­£åœ¨é‡Šæ”¾RealSenseèµ„æº...")
                self.pipeline.stop()
                self.pipeline = None
                print("âœ… RealSenseèµ„æºé‡Šæ”¾å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ é‡Šæ”¾èµ„æºæ—¶å‡ºé”™: {e}")
        finally:
            self.pipeline = None

    def calculate_object_position(self, pcd):
        """è®¡ç®—æ¡†é€‰åŒºåŸŸå†…ç‚¹äº‘çš„ç©ºé—´ä½ç½®å¹¶è½¬æ¢ä¸ºæœºæ¢°è‡‚åæ ‡"""
        # è·å–ç‚¹äº‘æ•°æ®
        points = np.asarray(pcd.points)
        colors = np.asarray(pcd.colors)
        
        # æ‰¾å‡ºçº¢è‰²ç‚¹çš„ç´¢å¼• (RGBå€¼æ¥è¿‘[1,0,0])
        red_mask = (colors[:, 0] > 0.8) & (colors[:, 1] < 0.2) & (colors[:, 2] < 0.2)
        red_points = points[red_mask]
        
        if len(red_points) < 3:  # å¦‚æœç‚¹å¤ªå°‘ï¼Œè¿”å›None
            print(f"æ¡†é€‰åŒºåŸŸå†…æœ‰æ•ˆç‚¹æ•°å¤ªå°‘: {len(red_points)}")
            return None, None
        
        # è®¡ç®—æœ‰æ•ˆç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
        # ä½¿ç”¨ç™¾åˆ†ä½æ•°å»é™¤å¼‚å¸¸å€¼
        percentile_low, percentile_high = 10, 90
        x_filtered = np.percentile(red_points[:, 0], [percentile_low, percentile_high])
        y_filtered = np.percentile(red_points[:, 1], [percentile_low, percentile_high])
        z_filtered = np.percentile(red_points[:, 2], [percentile_low, percentile_high])
        
        # åœ¨è¿‡æ»¤èŒƒå›´å†…çš„ç‚¹
        mask = ((red_points[:, 0] >= x_filtered[0]) & (red_points[:, 0] <= x_filtered[1]) &
                (red_points[:, 1] >= y_filtered[0]) & (red_points[:, 1] <= y_filtered[1]) &
                (red_points[:, 2] >= z_filtered[0]) & (red_points[:, 2] <= z_filtered[1]))
        
        filtered_points = red_points[mask]
        
        if len(filtered_points) < 3:
            print("è¿‡æ»¤åçš„æœ‰æ•ˆç‚¹å¤ªå°‘")
            return None, None
        
        # è®¡ç®—ä¸­å¿ƒç‚¹ï¼ˆä½¿ç”¨å‡å€¼ï¼‰
        center_point = np.mean(filtered_points, axis=0)
        
        # è·å–æœºæ¢°è‡‚å½“å‰ä½ç½®
        ROBOT_IP = "192.168.1.18"
        controller = RMJointRobotController(ROBOT_IP)
        if controller.connect():
            get_cmd = {"command": "get_current_arm_state"}
            response = controller.send_command(get_cmd)
            
            if response and "arm_state" in response:
                current_pose = response["arm_state"]["pose"]
                # æå–å½“å‰ä½ç½®ï¼ˆå•ä½è½¬æ¢ï¼š0.000001m -> mï¼‰
                X = current_pose[0] * 0.000001
                Y = current_pose[1] * 0.000001
                Z = current_pose[2] * 0.000001

                print(X)
                print(Y)
                print(Z)
                
                # è®¡ç®—ç›®æ ‡ä½ç½®
                x1, y1, z1 = center_point
                print(x1)
                print(y1)
                print(z1)
                X_new = X - x1 + 0.003884
                Y_new = Y + y1 - 0.09146
                Z_new = Z - z1 + 0.128848
                
                # è½¬æ¢å›æœºæ¢°è‡‚å•ä½ï¼ˆm -> 0.000001mï¼‰å¹¶ä¿æŒæ•´æ•°
                X_new = int(X_new * 1000000)
                Y_new = int(Y_new * 1000000)
                Z_new = int(Z_new * 1000000)
                
                # è¾“å‡ºæ–°çš„ä½å§¿
                print(f'"pose": [{X_new}, {Y_new}, {Z_new}, 3142, 0, -523]')
                
                return center_point.tolist(), None  # ä¸å†éœ€è¦è¿”å›relative_position
        
        return center_point.tolist(), None

class Point_geometry:
    def __init__(self):
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window()
        self.vis.get_render_option().point_size = 1.0
        self.vis.get_render_option().background_color = np.array([0.5, 0.5, 0.5])
        self.current_scene = None
        self.coordinate_frame = None

    def update_geometry(self, pcd):
        # ç§»é™¤æ—§çš„ç‚¹äº‘
        if self.current_scene is not None:
            view_control = self.vis.get_view_control()
            camera_params = view_control.convert_to_pinhole_camera_parameters()
            self.vis.remove_geometry(self.current_scene, False)
            
            # æ·»åŠ æ–°çš„åæ ‡ç³»å’Œç‚¹äº‘
            self.current_scene = pcd
            self.coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=3, origin=[0, 0, 0])
            self.vis.add_geometry(self.current_scene, False)
            self.vis.poll_events()
            self.vis.update_renderer()
        else:
            # æ·»åŠ æ–°çš„åæ ‡ç³»å’Œç‚¹äº‘
            self.current_scene = pcd
            self.coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=3, origin=[0, 0, 0])
            self.vis.add_geometry(self.current_scene)

            self.vis.poll_events()
            self.vis.update_renderer()
            # é‡ç½®è§†è§’
            ctr = self.vis.get_view_control()
            ctr.set_front([0, 0, -1])  # è®¾ç½®ç›¸æœºæœå‘ï¼ˆæ²¿Zè½´è´Ÿæ–¹å‘ï¼‰
            ctr.set_lookat([0, 0, 0])  # è®¾ç½®è§‚å¯Ÿç‚¹ï¼ˆåŸç‚¹ï¼‰
            ctr.set_up([0, -1, 0])  # è®¾ç½®ç›¸æœºä¸Šæ–¹å‘

def main(args):
    # ç¦ç”¨æ‰€æœ‰è­¦å‘Š
    import warnings
    warnings.simplefilter("ignore")
    
    print("ğŸš€ å¯åŠ¨RealSense RGBæ¡†é€‰+é«˜æ•ˆç‚¹äº‘ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ç›¸æœºå¯ç”¨æ€§
    print("ğŸ” æ£€æŸ¥ç›¸æœºå¯ç”¨æ€§...")
    if not StereoCamera.check_camera_availability():
        print("âŒ ç›¸æœºä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   1. RealSenseç›¸æœºæ˜¯å¦æ­£ç¡®è¿æ¥")
        print("   2. æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºæ­£åœ¨ä½¿ç”¨ç›¸æœº")
        print("   3. USBè¿æ¥æ˜¯å¦ç¨³å®š")
        print("   4. RealSenseé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
        return
    
    # åˆ›å»ºç›¸æœºå¯¹è±¡
    camera = StereoCamera()
    camera.set_fps(args.fps)
    
    # ç°åœ¨ä½¿ç”¨RealSenseå†…ç½®æ·±åº¦ç®—æ³•ï¼Œæ— éœ€åŠ è½½å¤–éƒ¨æ¨¡å‹
    print("ğŸ“Š ä½¿ç”¨RealSenseå†…ç½®æ·±åº¦ç®—æ³•ï¼Œæ— éœ€åŠ è½½å¤–éƒ¨æ¨¡å‹")

    # åˆ›å»ºçª—å£
    cv2.namedWindow('RGB View for Selection', cv2.WINDOW_NORMAL)  # RGBå›¾åƒç”¨äºæ¡†é€‰
    cv2.namedWindow('Depth and RGB', cv2.WINDOW_NORMAL)        # æ·±åº¦å’ŒRGBå›¾åƒ
    cv2.setMouseCallback('RGB View for Selection', camera.mouse_callback)
    vis_scene = Point_geometry()

    try:
        camera.start_processing(None, args)  # ä¸éœ€è¦ä¼ é€’æ¨¡å‹
        
        while True:
            frame_data = camera.get_display_frame()
            if frame_data is not None:
                depth_frame, color_frame, rgb_img, pcd = frame_data
                
                # å‡†å¤‡RGBå›¾åƒæ˜¾ç¤ºï¼ˆç”¨äºæ¡†é€‰ï¼‰
                rgb_display = rgb_img.copy()
                if camera.drawing and camera.start_point and camera.end_point:
                    cv2.rectangle(rgb_display, camera.start_point, camera.end_point, (0, 255, 0), 2)
                elif camera.bbox and camera.bbox.active:
                    cv2.rectangle(rgb_display, 
                                (camera.bbox.x1, camera.bbox.y1),
                                (camera.bbox.x2, camera.bbox.y2),
                                (0, 255, 0), 2)

                # æ˜¾ç¤ºRGBå›¾åƒï¼ˆç”¨äºæ¡†é€‰ï¼‰
                cv2.imshow('RGB View for Selection', rgb_display)

                # æ˜¾ç¤ºæ·±åº¦å›¾å’ŒRGBå›¾åƒ
                # å°†æ·±åº¦å›¾è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
                if depth_frame:
                    depth_image = np.asanyarray(depth_frame.get_data())
                    # æ·±åº¦å›¾å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ç”¨äºæ˜¾ç¤º
                    depth_colormap = cv2.applyColorMap(
                        cv2.convertScaleAbs(depth_image, alpha=0.03), 
                        cv2.COLORMAP_JET
                    )
                else:
                    depth_colormap = np.zeros((480, 640, 3), dtype=np.uint8)
                
                # ç»„åˆæ·±åº¦å›¾å’ŒRGBå›¾åƒ
                combined = np.hstack([depth_colormap, rgb_img])
                cv2.putText(combined, f"Target FPS: {camera.fps}", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(combined, "Depth                                RGB", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)
                cv2.imshow('Depth and RGB', combined)
                
                # æ›´æ–°ç‚¹äº‘æ˜¾ç¤º
                vis_scene.update_geometry(pcd)

            key = cv2.waitKey(1)
            if key == ord('q'):
                camera.is_running = False
                break
            elif key == ord('c'):  # æ¸…é™¤æ¡†é€‰
                camera.bbox = None
            elif key == ord('s'):  # ä¿å­˜å½“å‰RGBå›¾åƒ
                if 'rgb_img' in locals():
                    os.makedirs('static', exist_ok=True)
                    cv2.imwrite('static/current_rgb.jpg', rgb_img)
                    print("å·²ä¿å­˜å½“å‰RGBå›¾åƒåˆ° static/current_rgb.jpg")

            time.sleep(1.0 / camera.fps)

    finally:
        camera.stop_processing()
        cv2.destroyAllWindows()

def parse_args():
    parser = argparse.ArgumentParser(description='RealSense RGBæ¡†é€‰+é«˜æ•ˆç‚¹äº‘ç”Ÿæˆå™¨')
    parser.add_argument('--fps', default=10, type=int, help='ç›¸æœºå¸§ç‡')
    parser.add_argument('--z_far', default=3, type=float, help='ç‚¹äº‘ä¸­æœ€å¤§æ·±åº¦çš„è£å‰ªå€¼')
    parser.add_argument('--denoise_cloud', type=int, default=0, help='æ˜¯å¦å¯¹ç‚¹äº‘è¿›è¡Œå»å™ª')
    parser.add_argument('--denoise_nb_points', type=int, default=20, help='å»å™ªæ—¶çš„é‚»åŸŸç‚¹æ•°')

    args = parser.parse_args()
    return args

if __name__ == '__main__':
    args = parse_args()
    main(args) 